
# Clinical Sample Management Microservice

## ğŸ§ª Project Description

This service is a backend microservice designed to manage biological samples collected in clinical trials. It was developed as part of a technical challenge for the Backend Engineer position.

The microservice supports operations such as creating, reading, filtering, authentication, and storage of samples, with a focus on scalability and future integration with AI agents and analytical systems.

---

## ğŸš€ Technologies

- **Python 3.11**
- **FastAPI** â€” lightweight and fast framework for building REST APIs
- **MongoDB** â€” for storing biological samples (flexibility and scalability)
- **PostgreSQL (asyncpg)** â€” for storing user data (ACID compliance, normalization)
- **SQLAlchemy Async ORM**
- **Docker / docker-compose** â€” environment isolation and ease of launch
- **Pytest + httpx + aiosqlite** â€” unit and integration testing
- **Pydantic** â€” validation and serialization

---

## ğŸ“¦ How to Run

### 1. Clone the repository

```bash
git clone https://github.com/AlexnderKukachev/research_service.git
cd research_service
```

### 2. Create `.env` file based on example

```bash
cp .env.example .env
```
For local setup set the next variable like follow:
MONGODB_URI=mongodb://mongo:27017
POSTGRES_URI=postgresql+asyncpg://postgres:postgres@postgres/research_users
DB_NAME=research_db

### 3. Run the service

```bash
docker-compose up --build
```

API will be available at: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## âœ… Authentication

To access protected routes:

```http
POST /token
Body: form-data
  - username: <username>
  - password: <password>
```

Response:

```json
{
  "access_token": "<JWT>",
  "token_type": "bearer"
}
```

Add token to the header:

```
Authorization: Bearer <access_token>
```

---

## ğŸ§ª Testing

```bash
docker-compose -f docker-compose.yml -f docker-compose.test.yml up --build
```

Or manually:

```bash
docker-compose run app pytest
```

---

## ğŸ“ Project Structure

```
research_service/
â”œâ”€â”€ auth.py            # Authentication and tokens
â”œâ”€â”€ crud.py            # Business logic for DB access
â”œâ”€â”€ database.py        # PostgreSQL and MongoDB setup
â”œâ”€â”€ main.py            # Entrypoint + route handlers
â”œâ”€â”€ models.py          # SQLAlchemy models
â”œâ”€â”€ schemas.py         # Pydantic schemas
â”œâ”€â”€ config.py          # .env configuration
â””â”€â”€ tests/             # Unit and integration tests
```

---

## ğŸ§  Completed Features

- [x] CRUD operations for samples: create, read, filter, update, delete
- [x] JWT-based authentication
- [x] Input data validation
- [x] Dockerfile + docker-compose support
- [x] Logging
- [x] Async access to PostgreSQL and MongoDB
- [x] Unit and integration test coverage
- [x] Action logging

---

## âš ï¸ What Could Be Improved with More Time

- [ ] Add database migrations (e.g., Alembic)
- [ ] Implement caching (Redis)
- [ ] Define user roles (e.g., admin, technical)
- [ ] Add observability tools (OpenTelemetry, Prometheus)
- [ ] Persist logs to file or external service (ELK, Sentry)

---

## âš–ï¸ Trade-offs

- MongoDB was chosen for storing samples due to its flexible and schema-less nature.
- PostgreSQL was used for user data due to strict schema needs and ease of implementing secure authentication.
- Alembic migrations were skipped to save time (4-hour limit).
- No frontend was implemented â€” the service is intended to be integrated with UI or AI agents later.

---

## ğŸ¤– AI Usage

The service was partially developed using **ChatGPT 4.0** as a code generation and productivity tool. All architectural and technical decisions were made manually.
